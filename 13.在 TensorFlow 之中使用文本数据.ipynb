{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dd1d6140",
   "metadata": {},
   "source": [
    "    在之前的学习之中，我们曾经学习过如何进行文本分类，但是归根结底我们都是采用 TensorFlow 内置的 API 来直接获取数据集的 Dataset ，而没有真正的从文本文件中加载数据集。\n",
    "\n",
    "    在这节课之中，我们学习了如何在 TensorFlow 之中使用文本数据。总体而言，在大多数的学习任务之中都需要我们手动载入文本数据，我们一方面可以通过 tf.data.TextLineDataset 加载文本数据，另外一方面我们需要使用 tensorflow_dataset.features.text.Tokenizer 进行文本的编码处理。\n",
    "\n",
    "    在实际的机器学习任务之中，我们的数据集不可能每个都由 TensorFlow 提供，大多数的数据都是我们自行加载的。而对于文本数据，我们使用最多的数据格式就是 txt 数据格式，因此这节课我们来学习如何从文本文件中使用文本数据。\n",
    "\n",
    "    要使用文本数据，我们大致可以分为两个步骤：\n",
    "    a.使用 tf.data.TextLineDataset 加载文本数据；\n",
    "    b.使用编码将数据进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. 使用 tf.data.TextLineDataset 加载文本数据\n",
    "在 TensorFlow 之中加载文本数据最常用的方式就是采用 TensorFlow 中的内置函数使用 tf.data.TextLineDataset 加载文本数据进行加载。\n",
    "\n",
    "由于该 API 的存在，在 TensorFlow 之中加载数据变得非常简单、快捷。\n",
    "\n",
    "在这里，我们先使用谷歌仓库中的 txt 作为一个示例，大家可以使用自己的 txt 文件进行测试。\n",
    "'''\n",
    "\n",
    "import tensorflow as tf \n",
    "import os\n",
    "\n",
    "txt_path=tf.keras.utils.get_file(\"derby.txt\",origin=\"https://storage.googleapis.com/download.tensorflow.org/data/illiad/derby.txt\")\n",
    "\n",
    "# 使用 tf.data.TextLineDataset 函数来加载 txt 文件，该函数会将其自动转化为 tf.data.Dataset 对象\n",
    "# 然后我们对每条数据进行了映射处理，因为数据集需要含有标签，而我们的 txt 不含标签\n",
    "# 因此我们使用 0 作为暂时的标签；\n",
    "dataset=tf.data.TextLineDataset(txt_path).map(lambda x:(x,0))\n",
    "\n",
    "# 再者我们使用 shuffle 对数据集进行了随机化处理，然后又进行了分批的处理\n",
    "dataset.shuffle(1000).batch(32)\n",
    "\n",
    "print(dataset)\n",
    "# 查看了前四条数据\n",
    "for data in labeled_dataset.take(4):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c15d18fe",
   "metadata": {},
   "source": [
    "于是我们可以得到结果：\n",
    "<MapDataset shapes: ((), ()), types: (tf.string, tf.int32)>\n",
    "(<tf.Tensor: shape=(), dtype=string, numpy=b\"\\xef\\xbb\\xbfOf Peleus' son, Achilles, sing, O Muse,\">, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(), dtype=string, numpy=b'The vengeance, deep and deadly; whence to Greece'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(), dtype=string, numpy=b'Unnumbered ills arose; which many a soul'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(), dtype=string, numpy=b'Of mighty warriors to the viewless shades'>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "  可以发现，我们已经成功创建了数据集，但是没有进行编码处理，这显然是不适合直接进行机器学习的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5978dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. 使用编码将数据进行编码\n",
    "我们可以使用 tensorflow_dataset.features.text.Tokenizer 对象进行编码处理\n",
    "该对象能够将接收到的句子进行编码。\n",
    "同时，我们可以通过 tensorflow_dataset.features.text.TokenTextEncoder 函数进行编码器的构建。\n",
    "'''\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# 进行编码处理\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocab = set()\n",
    "for text, l in dataset:\n",
    "  token = tokenizer.tokenize(text.numpy())\n",
    "  vocab.update(token)\n",
    "\n",
    "print(len(vocab))\n",
    "\n",
    "# 然后我们可以进行编码操作（以下映射方式参考于 TensorFlow 官方文档）：\n",
    "# 定义编码器\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocab)\n",
    "\n",
    "def encode(text, label):\n",
    "  encoded_text = encoder.encode(text.numpy())\n",
    "  return encoded_text, label\n",
    "\n",
    "# 使用tf.py_function进行映射\n",
    "# 这是因为，如果在 map 函数之中调用 Tensor.numpy() 函数会报错，\n",
    "# 因此需要使用 tf.py_function 进行映射操作；\n",
    "def encode_map_fn(text, label):\n",
    "  encoded_text, label = tf.py_function(encode, inp=[text, label], Tout=(tf.int32, tf.int32))\n",
    "\n",
    "  # 手动设置形状Shape\n",
    "  encoded_text.set_shape([None])\n",
    "  label.set_shape([])\n",
    "\n",
    "  return encoded_text, label\n",
    "\n",
    "# 进行编码处理\n",
    "encoded_data_set = dataset.map(encode_map_fn)\n",
    "print(encoded_data_set)\n",
    "for data in encoded_data_set.take(4):\n",
    "  print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a811d7bd",
   "metadata": {},
   "source": [
    "于是，我们可以得到输出：\n",
    "<MapDataset shapes: ((None,), ()), types: (tf.int32, tf.int32)>\n",
    "(<tf.Tensor: shape=(7,), dtype=int32, numpy=array([7755, 4839, 4383, 5722, 4996, 2065, 8059], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 855, 5184,  700, 8356, 5931, 5665, 4634, 7127], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(7,), dtype=int32, numpy=array([1620, 6817, 5649, 5461, 5505,  209, 3146], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "(<tf.Tensor: shape=(7,), dtype=int32, numpy=array([7755, 1810, 3656, 4634, 4920, 1136, 6789], dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
    "\n",
    "于是我们可以发现，我们的数据集已经成功编码，现在可以便可以使用该数据集进行模型的训练了。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
