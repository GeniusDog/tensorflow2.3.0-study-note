{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed9e7c",
   "metadata": {},
   "source": [
    "任务：图像分类网络的常用的网络层、如何处理图片数据以及整体程序的结构\n",
    "图片分类任务步骤：\n",
    "获取数据：使用内部API下载数据集再进行解析，存入ImageDataGenerator迭代器中\n",
    "数据预处理：归一化\n",
    "构建神经网络模型：图片常用到Conv2D卷积层和MaxPolling2D池化层\n",
    "编译模型、训练模型\n",
    "可视化结果训练过程，训练中的参数保存在history中，只要用工具画这个即可\n",
    "\n",
    "数据集： Kaggle 上的猫狗分类数据集\n",
    "- 训练集合 2000 张图片，包括 1000 张狗图片和 1000 张猫图片；\n",
    "- 验证（测试）集合 1000 张图片，包括 500 张狗图片和 500 张猫图片。\n",
    "\n",
    "注意：我的PC在运行代码块的时候，带不起来，然后就崩了.但是放在云平台上能运行，结果在最后，\n",
    "这里输出的图片线上没有标签，和预想的不一样，后面可以把matplotlib画线的库给学习一下，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7adced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os  #os 用于目录的相关操作\n",
    "import matplotlib.pyplot as plt  #plt 用于我们的图片绘制工作\n",
    "\n",
    "# 定义一些数据集合与训练的基本参数，留作后面训练之用\n",
    "BATCH_SIZE = 64 #批次的大小，我们会将 BATCH_SIZE 个图片数据同时送给模型进行训练，这个数值大家可以根据自己的内存大小或者显存大小进行调整\n",
    "TRAIN_NUM = 2000 #训练集的数量\n",
    "VALID_NUM = 1000 #验证集的数量 \n",
    "EPOCHS = 15 # 训练的周期数，将所有的数据通用模型训练一遍称为一个 EPOCH，一般来说，EPOCH 的数值越大，模型在训练集合上的准确率越高，相应的所需要的时间也更长\n",
    "Height = 128 # 图片的高度\n",
    "Width = 128 # 图片的长度\n",
    "\n",
    "\n",
    "# 进行数据的下载与解压\n",
    "dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "# 使用 Keras 内置的下载工具进行下载，返回的是数据集所在的路径\n",
    "path_download = os.path.dirname(tf.keras.utils.get_file('cats_and_dogs.zip',\n",
    "                                origin=dataset_url,\n",
    "                                extract=True))\n",
    "\n",
    "# 结合数据集的下载位置与其内部文件建构得到训练数据集与测试数据集所在的目录\n",
    "train_dataset_dir = path_download + '/cats_and_dogs_filtered/train'\n",
    "valid_dataset_dir = path_download + '/cats_and_dogs_filtered/validation'\n",
    "\n",
    "# 可以通过下面的方法来查看数据文件所在的目录\n",
    "# 报错：name 'cat_train_dir' is not defined\n",
    "# print(cat_train_dir, cat_validation_dir, dog_train_dir, dog_validation_dir)\n",
    "\n",
    "\n",
    "# 这里我们要使用 Keras 内部内置的 ImageDataGenerator 来作为迭代器产生数据\n",
    "'''\n",
    "在这里我们定义了两个图片数据迭代器，同时我们定义了 rescale 参数，\n",
    "在函数内部每张图片的每个像素数据都会乘以 1./255，以将其归一化到 [0, 1] 之间，\n",
    "因为机器学习之中模型的最好输入数据是在 [0, 1] 之间。\n",
    "'''\n",
    "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b66d63",
   "metadata": {},
   "source": [
    "   在这里我们定义了两个图片数据迭代器，同时我们定义了 rescale 参数，在函数内部每张图片的每个像素数据都会乘以 1./255，以将其归一化到 [0, 1] 之间，因为机器学习之中模型的最好输入数据是在 [0, 1] 之间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b0ebdc",
   "metadata": {},
   "source": [
    "然后我们使用文件夹中的数据来初始化这两个图片数据迭代器，这个功能是采用 flow_from_directory 函数来实现的："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a15151d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2499953817.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\dog\\AppData\\Local\\Temp\\ipykernel_56564\\2499953817.py\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    class_mode=\"binary\"\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "使用 Keras 内部内置的 ImageDataGenerator 来作为迭代器产生数据\n",
    "batch_size：数据批次的大小，我们之前定义为 64；\n",
    "directory：数据存放的文件夹；\n",
    "shuffle：数据是否打乱，这里我们选择进行打乱；\n",
    "target_size：输出图片的大小，这里我们将长宽都定义为 128；\n",
    "class_mode：分类模式，这里我们选择 “binary” 表示这是一个二分类问题，\n",
    "            如果是多分类问题，我们可以选择 “categorical”。\n",
    "'''\n",
    "train_data_generator=train_image_generator.flow_from_directory(\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                directory=train_dataset_dir,\n",
    "                                shuffle=True,\n",
    "                                target_size=(Height,Width),\n",
    "                                class_mode=\"binary\"\n",
    "                )\n",
    "\n",
    "valid_dataset_generator=valid_image_generator.flow_from_directory(\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                directory=valid_dataset_dir,\n",
    "                                shuffle=True,\n",
    "                                target_size(Height,Width)\n",
    "                                class_mode=\"binary\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a86779",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建模型,这里我们采用传统的顺序结构来定义我们的网络结构\n",
    "Conv2D：卷积层，用来提图片的特征；\n",
    "MaxPooling2D：池化层，用来降低计算量；\n",
    "一般来说，池化层都会跟在卷积层之后。\n",
    "'''\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,3,padding=\"same\",activation=\"relu\",\n",
    "                           input_shape=(Height,Width,3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32,3,padding=\"same\",activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(64,3,padding=\"same\",activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4bcf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "然后我们对模型进行编译：\n",
    "优化器我们选择最常用的 adam 优化器，同时我们在训练的过程中记录准确率（accuracy）；\n",
    "因为任务是二元分类，因此我们采用的是二元交叉熵（BinaryCrossentropy）；\n",
    "因为网络最后一层没有激活函数而直接输出，因此模型产生的数据实际是两个类别的可能性的大小；\n",
    "所以优化器会加上参数 from_logits=True，以表示输出为可能性大小，而不是具体类别\n",
    "'''\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f5d7c",
   "metadata": {},
   "source": [
    "运行上面代码我们可以得到网络的结构：\n",
    "Model: \"sequential_3\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "\n",
    "conv2d_9 (Conv2D)            (None, 128, 128, 16)      448       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 64, 64, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_10 (Conv2D)           (None, 64, 64, 32)        4640      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 32, 32, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_11 (Conv2D)           (None, 32, 32, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_11 (MaxPooling (None, 16, 16, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten_3 (Flatten)          (None, 16384)             0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 512)               8389120   \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 1)                 513       \n",
    "\n",
    "Total params: 8,413,217\n",
    "Trainable params: 8,413,217\n",
    "Non-trainable params: 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17dcf31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_56564\\3369014264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m同时将训练数据保存在\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0m对象之中\u001b[0m\u001b[0;31m：\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m '''\n\u001b[1;32m----> 5\u001b[1;33m history=model.fitgenerator(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_image_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTRAIN_NUM\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "在训练模型的时候，我们会使用之前定义好的图片数据迭代器，\n",
    "同时将训练数据保存在 history 对象之中：\n",
    "'''\n",
    "history=model.fit_generator(\n",
    "    train_image_generator,\n",
    "    steps_per_epoch=TRAIN_NUM // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    valid_dataset_data=valid_image_generator,\n",
    "    valid_steps=VALID_NUM // BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06520b7",
   "metadata": {},
   "source": [
    "通过训练，我们可以得到以下的输出：\n",
    "Epoch 1/15\n",
    "31/31 [==============================] - 41s 1s/step - loss: 0.7072 - accuracy: 0.5134 - val_loss: 0.6650 - val_accuracy: 0.5167\n",
    "Epoch 2/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.6540 - accuracy: 0.5826 - val_loss: 0.6381 - val_accuracy: 0.5448\n",
    "Epoch 3/15\n",
    "31/31 [==============================] - 39s 1s/step - loss: 0.5780 - accuracy: 0.6844 - val_loss: 0.5859 - val_accuracy: 0.7208\n",
    "Epoch 4/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.5245 - accuracy: 0.7485 - val_loss: 0.5550 - val_accuracy: 0.6719\n",
    "Epoch 5/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.4673 - accuracy: 0.7645 - val_loss: 0.5654 - val_accuracy: 0.6865\n",
    "Epoch 6/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.3968 - accuracy: 0.8110 - val_loss: 0.5929 - val_accuracy: 0.7208\n",
    "Epoch 7/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.3216 - accuracy: 0.8492 - val_loss: 0.6224 - val_accuracy: 0.7104\n",
    "Epoch 8/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.2577 - accuracy: 0.8879 - val_loss: 0.6871 - val_accuracy: 0.7115\n",
    "Epoch 9/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.2204 - accuracy: 0.9060 - val_loss: 0.6982 - val_accuracy: 0.7250\n",
    "Epoch 10/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.1633 - accuracy: 0.9329 - val_loss: 0.9962 - val_accuracy: 0.6896\n",
    "Epoch 11/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.1371 - accuracy: 0.9489 - val_loss: 0.8724 - val_accuracy: 0.6990\n",
    "Epoch 12/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.0937 - accuracy: 0.9654 - val_loss: 1.1101 - val_accuracy: 0.7052\n",
    "Epoch 13/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.0640 - accuracy: 0.9742 - val_loss: 1.0343 - val_accuracy: 0.7083\n",
    "Epoch 14/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 1.1627 - val_accuracy: 0.7167\n",
    "Epoch 15/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 1.2627 - val_accuracy: 0.7156\n",
    "\n",
    "输出准确率与损失值因人而异，在这里我们在训练集合上得到了 99.54% 的准确率，在验证集上得到了 71.56% 的准确率.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "可视化训练过程\n",
    "在上一步之中，我们特地将训练过程的数据记录进了 history 对象之中；\n",
    "history 对象中的 history 数据对象是一个字典型的结构，\n",
    "其中包含了我们在训练过程中的准确率与损失值等等\n",
    "于是我们将其可视化：plot 折线图\n",
    "\n",
    "\n",
    "\n",
    "最后图显示的结果分析：\n",
    "由此可以看出，随着训练的不断迭代，训练集合上的准确率不断上升，损失值不断下降；\n",
    "但是验证集上的准确率在第 3 个 Epoch 以后便趋于平稳，\n",
    "而损失值却在第 3 个 Epoch 之后逐渐上升。\n",
    "这就是我们在训练过程中遇到的过拟合，我们以后会有课程详细介绍过拟合\n",
    "'''\n",
    "acc=history.history[\"accuracy\"]\n",
    "loss=history.history['loss']\n",
    "\n",
    "val_acc=history.history['val_accuracy']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "# 第一个图片展示准确率的变化\n",
    "plt.plot(range(EPOCHS),acc,label=\"Train ACC\")\n",
    "plt.plot(range(EPOCHS),val_acc,label=\"Valid ACC\")\n",
    "plt.show()\n",
    "\n",
    "# 第二个图片展示损失值的变化\n",
    "plt.plot(range(EPOCHS),loss,label='Train loss')\n",
    "plt.plot(range(EPOCHS),val_loss,label='Valid Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "完整可运行代码：\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_download = os.path.dirname(tf.keras.utils.get_file('cats_and_dogs.zip', origin=dataset_url, extract=True))\n",
    "train_dataset_dir = path_download + '/cats_and_dogs_filtered/train'\n",
    "valid_dataset_dir = path_download + '/cats_and_dogs_filtered/validation'\n",
    "cat_train_dir = path_download + '/cats_and_dogs_filtered/train/cats'\n",
    "cat_validation_dir = path_download + '/cats_and_dogs_filtered/validation/cats'\n",
    "dog_train_dir = path_download + '/cats_and_dogs_filtered/train/dogss'\n",
    "dog_validation_dir = path_download + '/cats_and_dogs_filtered/validation/dogs'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_NUM = 2000\n",
    "VALID_NUM = 1000\n",
    "EPOCHS = 15\n",
    "Height = 128\n",
    "Width = 128\n",
    "\n",
    "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                              directory=train_dataset_dir,\n",
    "                              shuffle=True,\n",
    "                              target_size=(Height, Width),\n",
    "                              class_mode='binary')\n",
    "valid_data_generator = valid_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                              directory=valid_dataset_dir,\n",
    "                              shuffle=True,\n",
    "                              target_size=(Height, Width),\n",
    "                              class_mode='binary')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu',\n",
    "                input_shape=(Height, Width ,3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "       metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=TRAIN_NUM // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_data_generator,\n",
    "    validation_steps=VALID_NUM // BATCH_SIZE)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss=history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_ran = range(EPOCHS)\n",
    "\n",
    "plt.plot(epochs_ran, acc, label='Train Acc')\n",
    "plt.plot(epochs_ran, val_acc, label='Valid Acc')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs_ran, loss, label='Train Loss')\n",
    "plt.plot(epochs_ran, val_loss, label='Valid Loss')\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f7e94",
   "metadata": {},
   "source": [
    "在云平台上运行的结果：\n",
    "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
    "68608000/68606236 [==============================] - 8s 0us/step\n",
    "Found 2000 images belonging to 2 classes.\n",
    "Found 1000 images belonging to 2 classes.\n",
    "\n",
    "使用model.summary()打印出来模型的构建情况：\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "conv2d (Conv2D)              (None, 128, 128, 16)      448       \n",
    "_________________________________________________________________\n",
    "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 16384)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 512)               8389120   \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 1)                 513       \n",
    "Total params: 8,413,217\n",
    "Trainable params: 8,413,217\n",
    "Non-trainable params: 0\n",
    "\n",
    "模型训练的过程，模型没有评估：\n",
    "Epoch 1/15\n",
    "31/31 [==============================] - 563s 18s/step - loss: 0.8026 - accuracy: 0.5015 - val_loss: 0.6858 - val_accuracy: 0.5042\n",
    "Epoch 2/15\n",
    "31/31 [==============================] - 356s 11s/step - loss: 0.6750 - accuracy: 0.5325 - val_loss: 0.6383 - val_accuracy: 0.6104\n",
    "Epoch 3/15\n",
    "31/31 [==============================] - 352s 11s/step - loss: 0.6306 - accuracy: 0.6121 - val_loss: 0.6086 - val_accuracy: 0.6583\n",
    "Epoch 4/15\n",
    "31/31 [==============================] - 328s 11s/step - loss: 0.5579 - accuracy: 0.6829 - val_loss: 0.6179 - val_accuracy: 0.6740\n",
    "Epoch 5/15\n",
    "31/31 [==============================] - 335s 11s/step - loss: 0.4930 - accuracy: 0.7438 - val_loss: 0.5693 - val_accuracy: 0.7354\n",
    "Epoch 6/15\n",
    "31/31 [==============================] - 371s 12s/step - loss: 0.4871 - accuracy: 0.7448 - val_loss: 0.5866 - val_accuracy: 0.6865\n",
    "Epoch 7/15\n",
    "31/31 [==============================] - 415s 13s/step - loss: 0.4367 - accuracy: 0.7707 - val_loss: 0.5938 - val_accuracy: 0.6854\n",
    "Epoch 8/15\n",
    "31/31 [==============================] - 478s 15s/step - loss: 0.3701 - accuracy: 0.8228 - val_loss: 0.6552 - val_accuracy: 0.6573\n",
    "Epoch 9/15\n",
    "31/31 [==============================] - 475s 15s/step - loss: 0.3330 - accuracy: 0.8487 - val_loss: 0.6219 - val_accuracy: 0.7198\n",
    "Epoch 10/15\n",
    "31/31 [==============================] - 478s 15s/step - loss: 0.2704 - accuracy: 0.8683 - val_loss: 0.7226 - val_accuracy: 0.7031\n",
    "Epoch 11/15\n",
    "31/31 [==============================] - 476s 15s/step - loss: 0.2363 - accuracy: 0.8998 - val_loss: 0.7711 - val_accuracy: 0.6885\n",
    "Epoch 12/15\n",
    "31/31 [==============================] - 443s 14s/step - loss: 0.1810 - accuracy: 0.9267 - val_loss: 0.8393 - val_accuracy: 0.6979\n",
    "Epoch 13/15\n",
    "31/31 [==============================] - 356s 11s/step - loss: 0.1441 - accuracy: 0.9473 - val_loss: 0.8402 - val_accuracy: 0.7167\n",
    "Epoch 14/15\n",
    "31/31 [==============================] - 344s 11s/step - loss: 0.1153 - accuracy: 0.9607 - val_loss: 0.9459 - val_accuracy: 0.7208\n",
    "Epoch 15/15\n",
    "31/31 [==============================] - 347s 11s/step - loss: 0.0952 - accuracy: 0.9675 - val_loss: 1.0133 - val_accuracy: 0.7177\n",
    "\n",
    "模型训练集上的正确率：96.75%\n",
    "模型验证集上的正确率：73.54%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cedbd43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
