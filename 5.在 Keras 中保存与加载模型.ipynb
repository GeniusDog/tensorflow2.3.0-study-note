{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a593e0",
   "metadata": {},
   "source": [
    "在我们之前的学习之中，我们所训练到的模型都没有经过保存，也就是所我们得到的模型的结构和参数都是存在于内存之中的，当我们关闭程序的时候这些模型和参数都会消失；如果我们想要使用该模型的话就需要再次训练模型。\n",
    "\n",
    "【心得】\n",
    "如果是加载参数的方法，那么加载函数要放在模型编译之前\n",
    "如果是保存参数，要么实在训练完成之后一次性保存，要么实在每次的epoch中保存\n",
    "\n",
    "1. 定义模型结构\n",
    "由于我们这节课的重点在模型的保存，而不是网络的结构，因此我们使用之前的网络结构： fashion_mnist 分类的网络结构。\n",
    "具体的网络代码为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df93cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 使用内置的数据集合来加载数据\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 预处理图片数据，使其归一化\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "'''\n",
    "这里多定义了一个函数get_model，函数返回值是个model\n",
    "使用函数构建模型\n",
    "'''\n",
    "def get_model():\n",
    "    # 定义网络结构\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "  return model\n",
    "# 调用函数构建模型\n",
    "modle = get_model()\n",
    "\n",
    "# 编译模型：sparse_categorical_crossentropy为交叉熵损失函数\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e12940",
   "metadata": {},
   "source": [
    "在这里我们不仅仅定义了网络的基本结构，同时也载入了基本的图片数据，从而便于后面的训练以及模型保存等操作。\n",
    "\n",
    "2. 在训练结束后保存模型参数、加载模型参数\n",
    "我们可以在训练之前直接保存模型参数，但是因为这样的参数是未经过训练的，因此没有太有价值的意义，因此我们在保存模型之前要先训练模型。\n",
    "我们可以通过以下代码来训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34228a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34343442",
   "metadata": {},
   "source": [
    "2.1 保存模型参数\n",
    "在训练结束之后我们可以手动进行模型参数的保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "保存模型参数\n",
    "通过这样的操作，我们便可以将我们模型的参数保存至当前目录的 “checkpoints” 文件夹下面，\n",
    "并且名命为 ckpt 。\n",
    "'''\n",
    "model.save_weights('./checkpoints/ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31de700",
   "metadata": {},
   "source": [
    "我们可以查看该文件夹下面的文件，可以看到文件夹下面包括三个文件：\n",
    "79  checkpoint\n",
    "1.2K  checkpoints.index\n",
    "2.4M  checkpoints.data-00000-of-00001\n",
    "这三个文件之中保存的就是我们的模型的参数。\n",
    "\n",
    "2.2 加载模型参数\n",
    "如果我们需要加载我们的模型，我们只需要经过以下两步即可：\n",
    "- 定义网络结构；\n",
    "- 按照保存路径来载入参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dfda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "加载模型参数\n",
    "'''\n",
    "# 创建模型结构\n",
    "model = get_model()\n",
    "\n",
    "# 加载参数\n",
    "model.load_weights('./checkpoints/ckpt')\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "# 评估模型\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51adbfb7",
   "metadata": {},
   "source": [
    "3. 使用回调保存模型参数\n",
    "前面我们知道了如何在模型训练结束后保存模型，那么如何让模型在训练的过程中自动保存模型呢？那便就需要用到 TensorFlow 的“回调函数”这个功能，这个功能允许我们定义一系列的事件，并让其在训练的过程之中执行。在这个例子之中，我们可以让它在每个 Epoch 结束的时候保存模型参数。于是我们首先定义了模型保存的回调函数，然后我们又在在 fit 函数之中使用 callbacks 参数来将其传入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe93861",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TensorFlow 的“回调函数”功能:定义了模型保存的回调函数\n",
    "cp_callback 中的几个参数大家需要注意一下：\n",
    "file_path: 与手动保存模型一样，定义了模型参数保存的路径；\n",
    "save_weights_only: 是否只保存模型参数，一般而言只保存参数的文件会比全部保存的文件小很多，\n",
    "                    因此我们一般只是保存网络参数。\n",
    "'''\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./checkpoints2/ckpt', save_weights_only=True)\n",
    "\n",
    "# 让其在每个 Epoch 结束的时候保存模型参数 \n",
    "model.fit(x_train,\n",
    "          y_train,  \n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afc1ea",
   "metadata": {},
   "source": [
    "我们可以看到，在每个 Epoch 结束后，模型都会进行模型参数的保存:\n",
    "Epoch 6/10\n",
    "1868/1875 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8985\n",
    "Epoch 00006: saving model to ./checkpoints2/ckpt\n",
    "INFO:tensorflow:Assets written to: ./checkpoints2/ckpt/assets\n",
    "于是我们便可以使得模型能够自动地保存模型参数。\n",
    "\n",
    "保存参数的优点：\n",
    "这样可以避免因为意外情况导致程序意外停止时，前面所有的训练都前功尽弃的情况。因为我们可以加载最近一次保存的模型继续训练。\n",
    "如果想要加载模型，那么便和手动加载模型一样即可：\n",
    "model.load_weights('./checkpoints2/ckpt')\n",
    "\n",
    "4. 保存模型与保存参数\n",
    "前面的保存都是只保存网络中的各种参数，而没有保存网络的模型。相比较而言而这主要有以下差别：\n",
    "- 保存参数的文件较小，而保存整个模型的文件较大；\n",
    "- 加载参数速度较快，而加载整个模型较慢；\n",
    "- 保存参数不包含网络结构，而保存整个模型则包含网络的结构。\n",
    "\n",
    "4.1 在训练结束后手动保存与加载整个模型\n",
    "和之前的操作一样，只是我们需要换一下保存的API函数：\n",
    "model.save('saved_model/model1')   # 这个是保存模型\n",
    "model.save_weights('./checkpoints/ckpt')  # 这个是保存参数\n",
    "当我们需要加载模型的时候，我们需要使用以下方法来加载模型：\n",
    "model = tf.keras.models.load_model('saved_model/model1')# 这个是加载模型\n",
    "model.load_weights('./checkpoints2/ckpt') #这个是加载参数\n",
    "\n",
    "4.2 在回调之中保存整个模型\n",
    "在回调之中保存整个模型比较简单，我们只需要将 save_weights_only 参数设置为 False 即可：\n",
    "save_weights_only: 是否只保存模型参数，一般而言只保存参数的文件会比全部保存的文件小很多，因此我们一般只是保存网络参数。\n",
    "save_weights_only=False # 模型的回调函数\n",
    "save_weights_only=True # 模型中参数的回调函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93830531",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./checkpoints3/ckpt', save_weights_only=False)\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train,  \n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d90ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "根据本节课的内容写一个保存模型中参数的程序\n",
    "任务：采用回调函数保存每次的模型参数\n",
    "这里不加载保存的参数了，可以直接跑到文件夹中\n",
    "如果是加载参数的方法，那么加载函数要放在模型编译之前\n",
    "如果是保存参数，要么实在训练完成之后一次性保存，要么实在每次的epoch\n",
    "'''\n",
    "import tensorflow as tf\n",
    "\n",
    "# 使用内置的数据集合来加载数据\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 预处理图片数据，使其归一化\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# 打印构建的网络模型\n",
    "model.summary()\n",
    "\n",
    "# 编译模型：sparse_categorical_crossentropy为交叉熵损失函数\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 参数的回调函数，True即可\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./checkpoints2/ckpt', save_weights_only=True)\n",
    "\n",
    "# 让其在每个 Epoch 结束的时候保存模型参数 \n",
    "model.fit(x_train,\n",
    "          y_train,  \n",
    "          epochs=10,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[cp_callback])\n",
    "\n",
    "# 评估模型\n",
    "model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "71d8b833",
   "metadata": {},
   "source": [
    "在云平台的运行结果：\n",
    "模型网络结构：\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "flatten (Flatten)            (None, 784)               0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 256)               200960    \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 10)                2570      \n",
    "=================================================================\n",
    "Total params: 203,530\n",
    "Trainable params: 203,530\n",
    "Non-trainable params: 0\n",
    "\n",
    "训练的过程：\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "1875/1875 [==============================] - 257s 137ms/step - loss: 0.4889 - accuracy: 0.8263 - val_loss: 0.4428 - val_accuracy: 0.8360\n",
    "Epoch 2/10\n",
    "1875/1875 [==============================] - 186s 99ms/step - loss: 0.3653 - accuracy: 0.8663 - val_loss: 0.3981 - val_accuracy: 0.8572\n",
    "Epoch 3/10\n",
    "1875/1875 [==============================] - 177s 94ms/step - loss: 0.3280 - accuracy: 0.8792 - val_loss: 0.3813 - val_accuracy: 0.8614\n",
    "Epoch 4/10\n",
    "1875/1875 [==============================] - 177s 94ms/step - loss: 0.3058 - accuracy: 0.8868 - val_loss: 0.3378 - val_accuracy: 0.8816\n",
    "Epoch 5/10\n",
    "1875/1875 [==============================] - 178s 95ms/step - loss: 0.2849 - accuracy: 0.8947 - val_loss: 0.3348 - val_accuracy: 0.8790\n",
    "Epoch 6/10\n",
    "1875/1875 [==============================] - 177s 94ms/step - loss: 0.2698 - accuracy: 0.8996 - val_loss: 0.3271 - val_accuracy: 0.8814\n",
    "Epoch 7/10\n",
    "1875/1875 [==============================] - 178s 95ms/step - loss: 0.2574 - accuracy: 0.9043 - val_loss: 0.3349 - val_accuracy: 0.8821\n",
    "Epoch 8/10\n",
    "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2458 - accuracy: 0.9086 - val_loss: 0.3435 - val_accuracy: 0.8825\n",
    "Epoch 9/10\n",
    "1875/1875 [==============================] - 174s 93ms/step - loss: 0.2367 - accuracy: 0.9113 - val_loss: 0.3234 - val_accuracy: 0.8857\n",
    "Epoch 10/10\n",
    "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2265 - accuracy: 0.9141 - val_loss: 0.3249 - val_accuracy: 0.8850\n",
    "313/313 - 8s - loss: 0.3249 - accuracy: 0.8850\n",
    "\n",
    "模型评估的结果：\n",
    "[0.32488903403282166, 0.8849999904632568]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
