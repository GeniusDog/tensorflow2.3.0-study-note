{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 学习用tensorflow搭建基本的神经网络结构\n",
    "# 版本：tensorflow==2.0 python=3.7\n",
    "\n",
    "TensorFlow 一般的程序的结构都是以下的顺序：\n",
    "- 引入所需要的包\n",
    "- 加载并预处理数据\n",
    "- 编写模型结构\n",
    "- 编译模型或 Build 模型\n",
    "- 训练模型与保存模型\n",
    "- 评估模型\n",
    "\n",
    "本次运行任务：如何根据输入的图片训练模型，从而使得模型可以根据输入的图片来预测其属于哪一个类别。\n",
    "数据集：fashion_mnist\n",
    "fashion_mnist 数据集合的 10 个类别为：[\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]。\n",
    "即为：[“T恤/上衣”、“裤子”、“套头衫”、“连衣裙”、“外套”、“凉鞋”、“衬衫”、“运动鞋”、“包包”、“踝靴”]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 查看tensorflow的版本：2.0\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用内置的数据集合来加载数据:fashion_mnist,6万条数据为训练集合，1万条为测试集合\n",
    "# 每个数据都是 28*28 的灰度图片数据，而每个数据的标签分为 10 个类别\n",
    "# 首先使用 tf.keras 中的 datasets 载入了fashion_mnist 数据集合，该函数返回的是两个元组：\n",
    "# 第一个元组为（训练数据的图片，训练数据的标签）\n",
    "# 第二个元组为（测试数据的图片，测试数据的标签）\n",
    "\n",
    "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# 预处理图片数据，使其归一化(弄清归一化和标准化的原理)\n",
    "# 在这里除以的255原因：\n",
    "    # 消除不同数据之间纲量的影响、\n",
    "    # 为了正常显示这个灰度图像\n",
    "    # 图片数据的每个像素都是 [0, 255] 的整数\n",
    "    # 因此我们可以将所有的图片数据除以 255 ，从而进行归一化\n",
    "# img/255.0 范围为[0, 1]\n",
    "# img/127.5 - 1 范围为[-1, 1]\n",
    "x_train,x_test=x_train/255.0,x_test/255.0\n",
    "\n",
    "# 定义网络结构,模型由三层组成\n",
    "# Flatten 层，这一层负责将二维的图片数据变成一维的数组数据，\n",
    "    # 比如我们输入的图片数据为 28*28 的二维数组，\n",
    "    # 那么 Flatten 层将会把其变为长度为 784 的一维数组\n",
    "    # 即相当于将二维数组拉直\n",
    "# Dense 层，全连接层，这一层的单元数为 10 个，\n",
    "    # 分别对应着我们的 10 个类别标签，激活函数为 “softmax” ，\n",
    "    # 表示它会计算每个类别的可能性，从而取可能性最大的类别作为输出的结果\n",
    "# \n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "# 优化器的选择，优化器代表着如何对网络中的参数进行优化，这里采用的是 “adam” 优化器，也是一种最普遍的优化器\n",
    "# 损失函数，损失函数意味着我们如何对“模型判断错误的惩罚”的衡量方式；\n",
    "# 换句话说，我们可以暂且理解成损失函数表示“模型判断出错的程度”。\n",
    "# 对于这种分类的问题，我们一般采用的是 “sparse_categorical_crossentropy” ，交叉熵来衡量。\n",
    "# Metrics，表示我们在训练的过程中要记录的数据，在这里我们记录了 “accuracy” ，也就是准确率\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "# 我们使用我们预先加载好的数据进行模型的训练\n",
    "# 在这里我们设置训练的循环数（ epoch ）为 5，表示我们会在数据集上循环 5 次\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 评估模型\n",
    "# 最后我们进行模型的评估，我们使用 x_test, y_test 对我们的模型进行相应的评估\n",
    "model.evaluate(x_test,  y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/5\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4865 - accuracy: 0.8283\n",
    "Epoch 2/5\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3644 - accuracy: 0.8693\n",
    "Epoch 3/5\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3287 - accuracy: 0.8795\n",
    "Epoch 4/5\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3048 - accuracy: 0.8874\n",
    "Epoch 5/5\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2864 - accuracy: 0.8938\n",
    "313/313 - 0s - loss: 0.3474 - accuracy: 0.8752\n",
    "[0.3474471867084503, 0.8751999735832214]\n",
    "\n",
    "由此可以看出，在训练集合上我们可以得到的最高的准确率为 87.52%，在测试集合上面的准确率为 87.519997%。\n",
    "\n",
    "\n",
    "镜像：TensorFlow  2.3.0  Python  3.8  Cuda  10.1 GPU\n",
    "TITAN Xp * 1  显存:12GB  CPU：8核 Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz\n",
    "内存:16GB  默认硬盘   系统盘:20 GB\n",
    "数据盘:免费:50GB SSD  \n",
    "使用云平台自己跑出来的结果为：\n",
    "Epoch 1/5\n",
    "1875/1875 [==============================] - 70s 37ms/step - loss: 0.4828 - accuracy: 0.83052s - - ETA: 0s - loss: 0.4829 - accuracy: \n",
    "Epoch 2/5\n",
    "1875/1875 [==============================] - 71s 38ms/step - loss: 0.3640 - accuracy: 0.8696\n",
    "Epoch 3/5\n",
    "1875/1875 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - 138s 74ms/step - loss: 0.3289 - accuracy: 0.8792\n",
    "Epoch 4/5\n",
    "1875/1875 [==============================] - 294s 157ms/step - loss: 0.3056 - accuracy: 0.8866\n",
    "Epoch 5/5\n",
    "1875/1875 [==============================] - 176s 94ms/step - loss: 0.2862 - accuracy: 0.8948\n",
    "313/313 [==============================] - 11s 34ms/step - loss: 0.3512 - accuracy: 0.8741\n",
    "[0.3512309193611145, 0.8741000294685364]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
