{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bb373264",
   "metadata": {},
   "source": [
    "    TensorBoard 的简介与快速上手\n",
    "    在之前的学习之中，我们已经对整个机器学习的结构有了一个大致的了解，但是我们在查看训练结果的时候只采用了两种可视化方法：\n",
    "    -使用 print 或者 log 来打印出一些日志与结果；\n",
    "    -使用 pyplot 来进行运行结果的可视化。\n",
    "    这两种结果各有优劣，第一种方法比较快速，能够在训练的时候直接查看，但是却不够直观；而第二种方法能够很直观的看到变化，但是却只能在训练结束后查看。有没有一种更好的方法来做到实时的、快速地、直观的查看呢？\n",
    "    那就是接下来几节课我们要学习的可视化工具 —— TensorBoard 。\n",
    "\n",
    "    1. 什么是 TensorBoard\n",
    "    TensorBoard 是一个工具包，它提供机器学习实验所需的可视化功能和工具。\n",
    "    值得注意的是，这里并没有明确说明要使用 TensorFlow 框架才能使用 TensorBoard 才能进行可视化工作。因此在实际中，很多的其他框架之中都内置了 TensorBoard 的工具，比如 PyTorch 等。总体而言，TensorBoard 是一个通用的，高效率的可视化工具。\n",
    "    具体而言，TensorBoard 可以实现以下的功能：\n",
    "        -对准确率、训练损失等参数进行可视化工作；\n",
    "        -对模型的架构进行可视化工作；\n",
    "        -对文本、图片、音频等媒体数据进行显示；\n",
    "        -查看权重、偏差的直方图；\n",
    "        -等等。\n",
    "    在这里，结合我们之前的训练例子，我们会更多地对前三点应用进行讲解。\n",
    "    \n",
    "    2. TensorBoard 的安装\n",
    "    一般情况下，当你安装 TensorFlow 的时候，已经默认帮你安装了 TensorBoard ，你只需要直接使用即可。但是也不排除某些特殊情况导致没有一起安装的情况。\n",
    "    \n",
    "    2.1 使用 PIP 安装\n",
    "    使用 PIP 安装比较简单，直接运行以下命令即可：\n",
    "    如果网络连接失败，可以参考以前的 TensorFlow 安装教程进行镜像的更换。\n",
    "    \n",
    "    2.2 使用 Anaconda 安装\n",
    "    如果有些同学是在 Anaconda 环境中进行的操作，那么推荐使用 Anaconda 命令进行安装：\n",
    "    通过这样的操作，我们就完成了 TensorBoard 的安装工作。\n",
    "    \n",
    "    3. TensorBoard 的快速上手使用\n",
    "    既然已经安装了 TensorBoard ，那么接下来我们便来看一下如何快速上手使用 TensorBoard 。\n",
    "    在这里，我们并不会进行更加深入的学习，也不会记录过于复杂的数据，这一节的目的是让大家对 TensorBoard 的整体使用流程有一个大致的了解。\n",
    "    首先，我们编写一段很平常的 Mnist 数据集的识别程序：\n",
    "    首先，我们进行数据集的获取与模型的构建："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75422f6d",
   "metadata": {},
   "source": [
    "    这是一个非常简单的线性程序，并且我们在模型编译的过程之中，指定记录的指标包括准确率（accuracy）。\n",
    "    然后我们进行模型的训练，同时进行相应的记录工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aba811",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "需要写在fit前面\n",
    "在这里，我们定义了一个回调，该回调是 TensorBoard 回调，\n",
    "该回调会在模型训练的时候进行日志的输出与构建工作。\n",
    "在这里我们只指定了一个参数：logdir：用于存放日志的目录。\n",
    "在后续的学习之中，我们会陆续学习到更多的参数与使用方法\n",
    "'''\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "\n",
    "model.fit(x=x_train, y=y_train, \n",
    "          epochs=3, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4250c0a7",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2252 - accuracy: 0.9344 - val_loss: 0.1082 - val_accuracy: 0.9684\n",
    "Epoch 2/3\n",
    "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0933 - accuracy: 0.9712 - val_loss: 0.1037 - val_accuracy: 0.9672\n",
    "Epoch 3/3\n",
    "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0622 - accuracy: 0.9807 - val_loss: 0.0705 - val_accuracy: 0.9783\n",
    "<tensorflow.python.keras.callbacks.History at 0x7f5500172f98>\n",
    "然后我们在当前目录下运行终端，并且输入命令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a53c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "其中 --logdir 的参数就是我们刚才指定的日志目录，\n",
    "通过运行以上命令，我们能得到相应的输出，通过输出我们可以发现，\n",
    "我们的 TensorBoard 目前在 localhost:6006 端口运行。\n",
    "在浏览器中打开 localhost:6006 ，我们就可以发现如下界面：\n",
    "'''\n",
    "tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a724006",
   "metadata": {},
   "source": [
    "    我们可以发现，该页面一共有两个选项卡，第一个选项卡包含了两个图表：\n",
    "    -训练集、测试集的准确率的图表；\n",
    "    -训练集、测试集的 Loss 的变化的图表。\n",
    "    其中第二个图表是自动生成的，也就是说 TensorBoard 会自动记录 Loss 变化；而第一个图表是由我们编译模型的时候指定的。\n",
    "\n",
    "    打开第二个选项卡，我们可以看到我们的网络的模型,该模型图展示了我们的网络模型，并且支持缩放等功能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
