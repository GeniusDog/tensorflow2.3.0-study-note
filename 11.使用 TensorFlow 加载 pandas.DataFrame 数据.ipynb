{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0fd230c3",
   "metadata": {},
   "source": [
    "    DataFrame，直译叫做“数据帧”，是一种二位数据，也就是说 DataFrame 是一种以表格形式存储数据的数据格式。\n",
    "    因为在机器学习之中最常用的表格数据格式是 CSV 格式的表格数据，因此机器学习领域的 DataFrame 绝大多数都是由 CSV 文件读取而来的。因此这节课我们主要学习如何从 CSV 数据之中读取 DataFrame 数据并且将其转化为 TensorFlow 能够使用的数据集合。\n",
    "   总体来说使用 DataFrame 加载数据大致分为四步：\n",
    "    a.使用 pandas 读取数据文件为 DataFrame；\n",
    "    b.对于DataFrame 进一步处理:预处理；\n",
    "    c.将 DataFrame 数据转化为 tf.data.Dataset；\n",
    "    d.进一步的数据处理与使用。 \n",
    "    那么在接下来我们会以一个之前学习过的泰坦尼克数据集作为简单的示例来带领大家使用 pandas.DataFrame 读取并加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6177ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. 使用 pandas 读取数据文件为 DataFrame\n",
    "首先我们需要在机器上安装 pandas，如果在安装 TensorFlow 的过程中没有自动安装 pandas ，\n",
    "那么我们就需要手动安装 pandas ：pip install pandas\n",
    "\n",
    "对于CSV文件，我们只需要使用 pd.read_csv() 函数就可以正确地读取CSV文件中的数据为 DataFrame 格式数据。\n",
    "'''\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "train_file = tf.keras.utils.get_file(\"train.csv\", \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "# 显示数据集合的前 5 条数据\n",
    "train_df.head()\n",
    "\n",
    "'''\n",
    "2. 对 DataFrame 进一步处理2. 对 DataFrame 进一步处理\n",
    "在这一个步骤之中，我们要进行的工作主要有：\n",
    "a.离散数据离散化，并且进行编码；\n",
    "b.分离标签与数据。\n",
    "对于离散数据离散化，我们可以使用 pandas 内置的 pd.Categorical() 方法进行；\n",
    "而后我们需要进行的是离散数据的编码，此时我们可以通过 DataFrame.xxx.cat.codes 来实现，\n",
    "其中 xxx 为 DataFrame 的属性。\n",
    "'''\n",
    "train_df['sex'] = pd.Categorical(train_df['sex'])\n",
    "train_df['sex'] = train_df.sex.cat.codes\n",
    "\n",
    "train_df['deck'] = pd.Categorical(train_df['deck'])\n",
    "train_df['deck'] = train_df.deck.cat.codes\n",
    "\n",
    "train_df['embark_town'] = pd.Categorical(train_df['embark_town'])\n",
    "train_df['embark_town'] = train_df.embark_town.cat.codes\n",
    "\n",
    "train_df['alone'] = pd.Categorical(train_df['alone'])\n",
    "train_df['alone'] = train_df.alone.cat.codes\n",
    "\n",
    "train_df['classes'] = pd.Categorical(train_df['class'])\n",
    "train_df['classes'] = train_df.classes.cat.codes\n",
    "# 要分离标签与数据，我们可以直接通过 pop() 函数来实现\n",
    "train_df.pop('class')\n",
    "labels = train_df.pop('survived')\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "'''\n",
    "3. 构建 tf.data.Dataset 数据集\n",
    "在这一步，我们可以使用之前的方法 tf.data.Dataset.from_tensor_slices 来进行数据集的构造。\n",
    "\n",
    "对于该示例，我们可以通过以下代码实现：\n",
    "'''\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_df.values, labels.values))\n",
    "train_dataset = train_dataset.shuffle(len(train_df)).batch(32)  # 打乱\n",
    "\n",
    "'''\n",
    "4. 数据集的使用\n",
    "在这里，我们使用和之前相似的模型进行演示，于是我们首先定义一个分类器，然后进行训练。\n",
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=30)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
