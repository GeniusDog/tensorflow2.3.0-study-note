{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b0d90079",
   "metadata": {},
   "source": [
    "小结：\n",
    "   由 TensorFlow 的名字我们就可以看出，其寓意表示张量（Tensor）流动（Flow）的意思。由此可见张量为 TensorFlow 的最核心的概念之一。 而这节课我们就来探究一下 TensorFlow 之中的数据核心概念：张量（Tensor）。张量也是向量。\n",
    "   学习了张量如何在tensorflow中表示，以及张量之间的操作：加减乘除、指数、幂运算等，还有关于张量的梯度运算，即求导运算。关键在于将公式表示出来，然后调用梯度函数来计算，这些属于高阶也是细节必备操作。\n",
    "   \n",
    "   1. 什么是张量\n",
    "   “张量是具有统一类型（称为 dtype ）的多维数组 ———— TensorFlow 官方定义”\n",
    "\n",
    "在 TensorFlow 之中，几乎所有的数据都要转换为张量进行运算，因此我们需要对张量有一定的了解。\n",
    "\n",
    "   简单来说，我们可以将张量看作多维数组，因为是多维数组，因此可以包含三维或者三维以上的维度。就像一维数组可以理解为直线，二维数组可以理解为平面一样。\n",
    "\n",
    "张量是 TensorFLow 之中以数据核心，张量的主要组成要素包括：\n",
    "a.名称（name）；\n",
    "b.形状（shape）；\n",
    "c.类型（dtype）。\n",
    "   名称就是张量的唯一标识符，在 TensorFlow 中可以自动维护，我们一般不需要对名称进行操作。其余的两个概念我们可以通过以下例子来理解：\n",
    "   x = tf.ones((64, 28, 28, 3), dtype=tf.float32)\n",
    "   由此我们构建了一个四维张量，它的形状是(64, 28, 28, 3)，其中它的第一维是 64 个维度，第二维与第三维都是28个维度，第四维是 3 个维度。而它的类型是我们所指定的 tf.float32 类型，也就是 32 位浮点类型。\n",
    "   \n",
    "   2. 张量的运算\n",
    "   在 TensorFlow 之中，如果我们想指定一个张量，我们可以通过如下操作实现：\n",
    "   x = tf.constant([1, 3, 5])\n",
    "   由此我们指定了一个形状为(3)，数据为[1, 3, 5]的一个张量，而默认的数据类型为int32 。\n",
    "   倘若我们需要指定全为 1 的张量，我们可以通过以下方式实现：\n",
    "   x1 = tf.ones([1, 3, 5])\n",
    "   相似的，如果我们需要指定全为 0 的向量，我们可以通过以下方式实现：\n",
    "   x2 = tf.zeros([1, 3, 5])\n",
    "   \n",
    "   2.1 加减乘除\n",
    "   在 TensorFlow 之中，我们可以使用内置的四则运算函数进行操作：\n",
    "   tf.add：进行张量的加法；\n",
    "   tf.subtract：进行张量的减法；\n",
    "   tf.multiply：进行张量的乘法；\n",
    "   tf.divid：进行张量的除法。\n",
    "   \n",
    "   但是 TensorFlow 已经对四则运算进行了重载，因此我们可以直接使用 + - * / 符号进行运算,也可以得到相同的结果。\n",
    "   \n",
    "   2.2 对数运算与指数运算\n",
    "    对于指数运算与对数运算，我们可以采用以下的函数：\n",
    "    tf.pow：实现幂运算，可以使用 ** 代替；\n",
    "    tf.exp：实现自然指数运算；\n",
    "    tf.math.log：实现自然对数运算，与 tf.exp 刚刚相反。\n",
    "\n",
    "   2.3 使用张量进行矩阵运算,即是矩阵运算的规则\n",
    "    使用张量进行矩阵运算的条件为：\n",
    "    - 两个张量形状除了最后两个维度外的所有形状必须相同,两者第一维形状相同；\n",
    "    - 两个张量形状最后两个维度需要符合 a * b 与 b * c的的格式。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d12a3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(3,), dtype=int32, numpy=array([1, 3, 5])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 以乘法为例，我们可以看一下使用方法：\n",
    "x1 = tf.constant([1, 3, 5])\n",
    "x2 = tf.constant([1, 3, 5])\n",
    "y = tf.multiply(x1, x2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2744bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.049131    1.0766661  -0.72545105  1.3430474   1.7125623\n",
      "    4.4472265 ]\n",
      "  [ 0.40998626 -0.6655391   0.9662531  -3.0774257   2.3997588\n",
      "   -2.9318395 ]\n",
      "  [ 0.40474272 -0.8235569   0.05176139  0.24035695 -1.8875339\n",
      "   -1.0367829 ]\n",
      "  [ 3.424913   -0.27058113  1.179635   -0.56035095  2.7353148\n",
      "    6.3356886 ]]\n",
      "\n",
      " [[-2.0779812   1.3340939  -2.1628723   0.10193045 -3.521513\n",
      "   -2.1257114 ]\n",
      "  [-0.06444946 -0.4527654   1.4186081   1.1001909   0.0803251\n",
      "    0.37437558]\n",
      "  [ 2.4723978  -3.0116735   1.5899609  -0.726071    1.3895258\n",
      "    2.3616471 ]\n",
      "  [ 2.3095815  -2.1163366   1.6093693  -1.4380711   2.0698168\n",
      "   -0.45315146]]\n",
      "\n",
      " [[-1.2965012  -0.01927695  1.0029209  -2.6229725   0.69450915\n",
      "    0.22143118]\n",
      "  [ 3.5630796  -2.4934924  -0.12148063 -0.7986152  -1.7744093\n",
      "    0.58742476]\n",
      "  [-5.8907638  -0.512251    1.1978624   1.1138319  -0.12734383\n",
      "   -0.6206355 ]\n",
      "  [-0.9943646   2.5887878  -0.83747756  2.25064     1.2873192\n",
      "    0.55390215]]], shape=(3, 4, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "其中a与b是固定形状的随机张量，因为两者第一维形状相同，\n",
    "而最后两维形状符合矩阵相乘的格式\n",
    "'''\n",
    "a = tf.random.normal([3,4,5])\n",
    "b = tf.random.normal([3,5,6])\n",
    "print(tf.matmul(a, b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbcc62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant((64, 28, 28, 3))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6221053",
   "metadata": {},
   "source": [
    "   3. 张量的梯度\n",
    "    在机器学习中我们最经常使用的就是张量的梯度了，张量的梯度可以理解为张量的微分。因为在机器学习之中我们需要不断地计算参数的导数来计算出参数的误差，从而对参数进行调整。\n",
    "\n",
    "    在 TensorFlow 之中，计算张量的梯度是通过 tf.GradientTape 来进行的，具体来说分为两步：\n",
    "    - 在梯度带中定义运算；\n",
    "    - 运算结束后从梯度带中得到梯度。\n",
    "    下面我们以一个简单的例子来展示一下如何求得梯度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15990771",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2\n",
    "\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx.numpy())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "097f0838",
   "metadata": {},
   "source": [
    "    在上面的例子之中，我们首先定义了一个常量 x，然后我们在梯度带中定义 y 为 x 的平方，然后我们便在记录的梯度带中求得 y 对于 x 的梯度，在这里就相当于导数。因为 x * *2 的导数为 2 * x，因此我们得到的梯度应该是 2 * 5 = 10。我们查看输出，果然结果是10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cdeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(tf.random.normal((3, 2)), name='a')\n",
    "b = tf.Variable(tf.zeros(2), name='b')\n",
    "x = [[1., 2., 3.]]\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = tf.matmul(x, a) + b\n",
    "  loss = tf.reduce_mean(y**2)  # 计算y**2的平均值\n",
    "\n",
    "[dl_da, dl_db] = tape.gradient(loss, [a, b])\n",
    "print(a)\n",
    "print(dl_da, dl_db)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e40d7b3b",
   "metadata": {},
   "source": [
    "  在这里我们定义了 a 和 b 两个张量，并定义了一个常数 x；然后我们在梯度带中计算了 y = a * x + b，然后又计算了 y 平方的平均值（赋值为 loss ）；\n",
    "  计算结束后我们计算了 loss 对于 a 和 b 的梯度，并将其输出。\n",
    "      <tf.Variable 'a:0' shape=(3, 2) dtype=float32, numpy=\n",
    "    array([[-0.16581778, -0.5726858 ],\n",
    "           [ 0.65533674,  0.8761684 ],\n",
    "           [ 0.7585775 , -1.0951476 ]], dtype=float32)>\n",
    "    tf.Tensor(\n",
    "    [[ 3.4205883 -2.1057918]\n",
    "     [ 6.8411765 -4.2115836]\n",
    "     [10.261765  -6.317375 ]], shape=(3, 2), dtype=float32) tf.Tensor([ 3.4205883 -2.1057918], shape=(2,), dtype=float32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
