{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d06df7c",
   "metadata": {},
   "source": [
    "    在 TensorFlow 之中进行数据增强\n",
    "    在我们之前的学习之中，我们所使用的数据都是进行一些 “简单的处理”，比如正则化、归一化、分批次等基本操作；这些操作都有一些特点，那就是在固定的数据集上进行处理，也就是说这些处理并不会改变数据的数量（甚至可能会减少数据的数量，比如数据筛选）。\n",
    "    那么这节课我们便来学习一下如何在 TensorFlow 之中数据增强，它可以增加数据量，从而可以使用更多样的数据来训练模型。\n",
    "\n",
    "    1. 什么是数据增强\n",
    "    关于数据增强，我们可以在 TensorFlow API 之中看到相关的定义：\n",
    "    A technique to increase the diversity of your training set by applying random (but realistic) transformations.\n",
    "    翻译一下就是：\n",
    "        数据增强是一种通过应用随机（但现实）的变换来增加训练集的多样性的技术。\n",
    "    简单来说，通过数据增强，我们可以将一些已经存在的数据进行相应的变换（可以选择将这些变换之后的数据增加到新的原来的数据集之中，也可以直接在原来的数据集上进行变换），从而实现数据种类多样性的增加。\n",
    "    数据增强常见于图像领域，因此这节课我们会以图像处理为例来解释如何在 TensorFlow 之中进行数据增强。\n",
    "    对于图片数据，常见的数据增强方式包括：\n",
    "        随机水平翻转：\n",
    "        随机的裁剪；\n",
    "        随机调整明亮程度；\n",
    "        其他方式等。\n",
    "        \n",
    "    2. 如何在 TensorFlow 之中进行图像数据增强\n",
    "    在 TensorFlow 之中进行图像数据增强的方式主要有两种：\n",
    "        使用 tf.keras 的预处理层进行图像数据增强；\n",
    "        使用 tf.image 进行数据增强。\n",
    "    这两种各有不同的特点，但是因为我们要采用 tf.keras 进行模型的构建，因此我们重点学习如何使用 tf.keras 的预处理层进行图像数据增强。\n",
    "\n",
    "    1. 如何使用 tf.keras 的预处理层进行图像数据增强\n",
    "    使用 tf.keras 的预处理层进行图像数据增强要使用的最主要的 API 包括在一下包之中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.layers.experimental.preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cac33732",
   "metadata": {},
   "source": [
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode): 将输入的图片进行随机翻转，一般我们会取 mode=“horizontal” ，因为这代表水平旋转；而 mode=“vertical” 则代表随机进行上下翻转；\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(): 按照旋转角度（单位为弧度） p 将输入的图片进行随机的旋转；\n",
    "    tf.keras.layers.experimental.preprocessing.RandomContrast()：按照 P 的概率将输入的图片进行随机的图像色相翻转；\n",
    "    tf.keras.layers.experimental.preprocessing.CenterCrop(height, width)：使用 height * width 的大小的裁剪框，在数据的中心进行裁剪。\n",
    "    在使用的过程之中，我们只需要将这些数据增强的网络层添加到网络的最底层即可\n",
    "    \n",
    "    2. 使用 tf.image 进行数据增强\n",
    "使用 tf.image 是 TensorFlow 最原生的一种增强方式，使用这种方式可以实现更多、更加个性化的数据增强。\n",
    "    其中包含的数据增强方式主要包括：\n",
    "        tf.image.flip_left_right (img)：将图片进行水平翻转；\n",
    "        tf.image.rgb_to_grayscale (img)：将 RGB 图像转化为灰度图像；\n",
    "        tf.image.adjust_saturation (image, f)：将 image 图像按照 f 参数进行饱和度的调节；\n",
    "        tf.image.adjust_brightness (image, f)：将 image 图像按照 f 参数进行亮度的调节；\n",
    "        tf.image.central_crop (image, central_fraction)：按照 p 的比例进行图片的中心裁剪，比如如果 p 是 0.5 ，那么裁剪后的长、宽就是原来图像的一半；\n",
    "        tf.image.rot90 (image)：将 image 图像逆时针旋转 90 度。\n",
    "    可以看到，很多的 tf.image 数据增强方式并不提供随机化选项，因此我们需要手动进行随机化。\n",
    "    也正是因为上述特性，tf.image 数据增强主要用在一些自定义的模型之中，从而可以实现数据增强的自定义化。\n",
    "    \n",
    "    3. 使用 tf.keras 的预处理层进行数据增强的实例\n",
    "    在这里，我们仍然采用我们熟悉的猫狗分类的例子来进行程序的演示，我们的代码和之前的代码相同，只是我们新增加了两个数据增强的处理层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 其中第一个层表示进行随机的水平和垂直翻转，\n",
    "    # 而第二个层表示按照 0.2 的弧度值进行随机旋转。\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\",\n",
    "                input_shape=(Height, Width ,3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整体的网络程序为:\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_download = os.path.dirname(tf.keras.utils.get_file('cats_and_dogs.zip', origin=dataset_url, extract=True))\n",
    "train_dataset_dir = path_download + '/cats_and_dogs_filtered/train'\n",
    "valid_dataset_dir = path_download + '/cats_and_dogs_filtered/validation'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TRAIN_NUM = 2000\n",
    "VALID_NUM = 1000\n",
    "EPOCHS = 15\n",
    "Height = 128\n",
    "Width = 128\n",
    "\n",
    "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "valid_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                              directory=train_dataset_dir,\n",
    "                              shuffle=True,\n",
    "                              target_size=(Height, Width),\n",
    "                              class_mode='binary')\n",
    "valid_data_generator = valid_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
    "                              directory=valid_dataset_dir,\n",
    "                              shuffle=True,\n",
    "                              target_size=(Height, Width),\n",
    "                              class_mode='binary')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\",\n",
    "                input_shape=(Height, Width ,3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    tf.keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "       metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=TRAIN_NUM // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_data_generator,\n",
    "    validation_steps=VALID_NUM // BATCH_SIZE)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss=history.history['loss']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_ran = range(EPOCHS)\n",
    "\n",
    "plt.plot(epochs_ran, acc, label='Train Acc')\n",
    "plt.plot(epochs_ran, val_acc, label='Valid Acc')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs_ran, loss, label='Train Loss')\n",
    "plt.plot(epochs_ran, val_loss, label='Valid Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19cf9403",
   "metadata": {},
   "source": [
    "    在训练结束后，我们可以得到如下结果，而这个结果与我们之前的结果有了一个良好的提升，最高达到了 79% 的准确率，因此我们认为我们的数据增强起到了一定的作用。\n",
    "    \n",
    "Found 2000 images belonging to 2 classes.\n",
    "Found 1000 images belonging to 2 classes.\n",
    "\n",
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "random_flip_1 (RandomFlip)   (None, 128, 128, 3)       0         \n",
    "_________________________________________________________________\n",
    "random_rotation_1 (RandomRot (None, 128, 128, 3)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 126, 126, 16)      448       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_6 (MaxPooling2 (None, 63, 63, 16)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 61, 61, 32)        4640      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_8 (Conv2D)            (None, 28, 28, 64)        18496     \n",
    "_________________________________________________________________\n",
    "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
    "_________________________________________________________________\n",
    "flatten_2 (Flatten)          (None, 12544)             0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 512)               6423040   \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 1)                 513       \n",
    "=================================================================\n",
    "Total params: 6,447,137\n",
    "Trainable params: 6,447,137\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "\n",
    "Epoch 1/15\n",
    "31/31 [==============================] - 40s 1s/step - loss: 0.7372 - accuracy: 0.5052 - val_loss: 0.6700 - val_accuracy: 0.5583\n",
    "......\n",
    "Epoch 11/15\n",
    "31/31 [==============================] - 41s 1s/step - loss: 0.5219 - accuracy: 0.8213 - val_loss: 0.5480 - val_accuracy: 0.7900\n",
    "......\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
